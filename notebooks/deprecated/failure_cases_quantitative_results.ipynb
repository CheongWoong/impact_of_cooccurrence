{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/cwkang/anaconda3/envs/cooccurrence_bias/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cooccurrence_matrix import CooccurrenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = CooccurrenceMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "\n",
    "filter = {}\n",
    "for w in stopword_list:\n",
    "    filter[w] = w\n",
    "punctuations = {\n",
    "    \"?\": \"?\",\n",
    "    \":\": \":\",\n",
    "    \"!\": \"!\",\n",
    "    \".\": \".\",\n",
    "    \",\": \",\",\n",
    "    \";\": \";\"\n",
    "}\n",
    "filter.update(punctuations)\n",
    "def filtering(text):\n",
    "    if text in filter:\n",
    "        return True\n",
    "\n",
    "def text_normalization_without_lemmatization(text):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    for token in tokens:\n",
    "        token_low = token.lower()\n",
    "        if filtering(token_low):\n",
    "            continue\n",
    "        result.append(token_low)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/LAMA_TREx/all.json\", 'r') as fin:\n",
    "    f_all = json.load(fin)\n",
    "\n",
    "uid_rel_map = {}\n",
    "uid_subj_map = {}\n",
    "rel_subj_objects = defaultdict(set)\n",
    "for example in f_all:\n",
    "    subj = example['subj']\n",
    "    rel = example['rel_id']\n",
    "    obj = example['output']\n",
    "\n",
    "    uid_subj_map[example['uid']] = subj\n",
    "    uid_rel_map[example['uid']] = rel\n",
    "    rel_subj_objects[rel+'_'+subj].add(obj.lower())\n",
    "for key in rel_subj_objects:\n",
    "    rel_subj_objects[key] = list(rel_subj_objects[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_125M\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5466.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 37% / 6094\n",
      "0 / 0% / 647\n",
      "1 / 14% / 2074\n",
      "2 / 39% / 1487\n",
      "3 / 63% / 888\n",
      "4 / 79% / 481\n",
      "5 / 87% / 244\n",
      "6 / 94% / 147\n",
      "7 / 97% / 126\n",
      "Failure cases\n",
      "total / 0.35 +- 0.26 / 0.48 +- 0.32 / 6094\n",
      "0 / 0.37 +- 0.28 / 1.0 +- 0.0 / 647\n",
      "1 / 0.37 +- 0.27 / 0.72 +- 0.14 / 2074\n",
      "2 / 0.35 +- 0.24 / 0.37 +- 0.07 / 1487\n",
      "3 / 0.34 +- 0.25 / 0.18 +- 0.04 / 888\n",
      "4 / 0.31 +- 0.26 / 0.09 +- 0.02 / 481\n",
      "5 / 0.3 +- 0.28 / 0.05 +- 0.01 / 244\n",
      "6 / 0.31 +- 0.27 / 0.02 +- 0.0 / 147\n",
      "7 / 0.32 +- 0.31 / 0.01 +- 0.0 / 126\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_125M_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5565.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 31% / 3906\n",
      "0 / 0% / 91\n",
      "1 / 6% / 1319\n",
      "2 / 18% / 935\n",
      "3 / 39% / 601\n",
      "4 / 60% / 414\n",
      "5 / 79% / 255\n",
      "6 / 89% / 164\n",
      "7 / 91% / 127\n",
      "Failure cases\n",
      "total / 0.23 +- 0.26 / 0.4 +- 0.29 / 3906\n",
      "0 / 0.4 +- 0.32 / 1.0 +- 0.0 / 91\n",
      "1 / 0.24 +- 0.25 / 0.71 +- 0.14 / 1319\n",
      "2 / 0.23 +- 0.24 / 0.37 +- 0.07 / 935\n",
      "3 / 0.23 +- 0.26 / 0.18 +- 0.03 / 601\n",
      "4 / 0.21 +- 0.24 / 0.09 +- 0.02 / 414\n",
      "5 / 0.23 +- 0.28 / 0.05 +- 0.01 / 255\n",
      "6 / 0.23 +- 0.27 / 0.02 +- 0.0 / 164\n",
      "7 / 0.22 +- 0.28 / 0.01 +- 0.0 / 127\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_1_3B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5494.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 39% / 5715\n",
      "0 / 0% / 634\n",
      "1 / 14% / 1897\n",
      "2 / 41% / 1329\n",
      "3 / 63% / 829\n",
      "4 / 82% / 467\n",
      "5 / 85% / 257\n",
      "6 / 90% / 172\n",
      "7 / 97% / 130\n",
      "Failure cases\n",
      "total / 0.36 +- 0.27 / 0.47 +- 0.32 / 5715\n",
      "0 / 0.37 +- 0.28 / 1.0 +- 0.0 / 634\n",
      "1 / 0.38 +- 0.27 / 0.72 +- 0.14 / 1897\n",
      "2 / 0.36 +- 0.25 / 0.37 +- 0.07 / 1329\n",
      "3 / 0.34 +- 0.26 / 0.18 +- 0.04 / 829\n",
      "4 / 0.31 +- 0.27 / 0.09 +- 0.02 / 467\n",
      "5 / 0.33 +- 0.3 / 0.05 +- 0.01 / 257\n",
      "6 / 0.34 +- 0.33 / 0.02 +- 0.0 / 172\n",
      "7 / 0.3 +- 0.3 / 0.01 +- 0.0 / 130\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_1_3B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5465.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 28% / 3525\n",
      "0 / 0% / 104\n",
      "1 / 6% / 1108\n",
      "2 / 19% / 854\n",
      "3 / 33% / 542\n",
      "4 / 50% / 378\n",
      "5 / 65% / 243\n",
      "6 / 75% / 166\n",
      "7 / 83% / 130\n",
      "Failure cases\n",
      "total / 0.2 +- 0.23 / 0.39 +- 0.3 / 3525\n",
      "0 / 0.35 +- 0.29 / 1.0 +- 0.0 / 104\n",
      "1 / 0.23 +- 0.25 / 0.71 +- 0.14 / 1108\n",
      "2 / 0.22 +- 0.23 / 0.37 +- 0.07 / 854\n",
      "3 / 0.18 +- 0.2 / 0.18 +- 0.03 / 542\n",
      "4 / 0.15 +- 0.18 / 0.09 +- 0.02 / 378\n",
      "5 / 0.13 +- 0.18 / 0.05 +- 0.01 / 243\n",
      "6 / 0.12 +- 0.19 / 0.02 +- 0.0 / 166\n",
      "7 / 0.13 +- 0.23 / 0.01 +- 0.0 / 130\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_2_7B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5480.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 37% / 5801\n",
      "0 / 0% / 610\n",
      "1 / 14% / 1971\n",
      "2 / 37% / 1385\n",
      "3 / 61% / 812\n",
      "4 / 77% / 463\n",
      "5 / 85% / 264\n",
      "6 / 94% / 169\n",
      "7 / 96% / 127\n",
      "Failure cases\n",
      "total / 0.35 +- 0.28 / 0.47 +- 0.32 / 5801\n",
      "0 / 0.4 +- 0.28 / 1.0 +- 0.0 / 610\n",
      "1 / 0.37 +- 0.27 / 0.72 +- 0.14 / 1971\n",
      "2 / 0.35 +- 0.26 / 0.37 +- 0.07 / 1385\n",
      "3 / 0.33 +- 0.27 / 0.18 +- 0.04 / 812\n",
      "4 / 0.31 +- 0.27 / 0.09 +- 0.02 / 463\n",
      "5 / 0.33 +- 0.3 / 0.05 +- 0.01 / 264\n",
      "6 / 0.33 +- 0.34 / 0.02 +- 0.0 / 169\n",
      "7 / 0.32 +- 0.33 / 0.01 +- 0.0 / 127\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_2_7B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5498.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 29% / 3351\n",
      "0 / 0% / 79\n",
      "1 / 7% / 1041\n",
      "2 / 20% / 808\n",
      "3 / 35% / 528\n",
      "4 / 51% / 379\n",
      "5 / 58% / 243\n",
      "6 / 68% / 155\n",
      "7 / 83% / 118\n",
      "Failure cases\n",
      "total / 0.21 +- 0.24 / 0.38 +- 0.29 / 3351\n",
      "0 / 0.39 +- 0.32 / 1.0 +- 0.0 / 79\n",
      "1 / 0.24 +- 0.26 / 0.72 +- 0.13 / 1041\n",
      "2 / 0.23 +- 0.24 / 0.37 +- 0.07 / 808\n",
      "3 / 0.2 +- 0.23 / 0.18 +- 0.03 / 528\n",
      "4 / 0.17 +- 0.22 / 0.09 +- 0.02 / 379\n",
      "5 / 0.12 +- 0.18 / 0.05 +- 0.01 / 243\n",
      "6 / 0.1 +- 0.19 / 0.02 +- 0.0 / 155\n",
      "7 / 0.08 +- 0.17 / 0.01 +- 0.0 / 118\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_j_6B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5299.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 38% / 5252\n",
      "0 / 0% / 479\n",
      "1 / 15% / 1742\n",
      "2 / 42% / 1251\n",
      "3 / 56% / 782\n",
      "4 / 70% / 440\n",
      "5 / 78% / 262\n",
      "6 / 85% / 167\n",
      "7 / 95% / 129\n",
      "Failure cases\n",
      "total / 0.35 +- 0.29 / 0.46 +- 0.32 / 5252\n",
      "0 / 0.42 +- 0.31 / 1.0 +- 0.0 / 479\n",
      "1 / 0.38 +- 0.28 / 0.72 +- 0.14 / 1742\n",
      "2 / 0.37 +- 0.27 / 0.37 +- 0.07 / 1251\n",
      "3 / 0.31 +- 0.26 / 0.18 +- 0.04 / 782\n",
      "4 / 0.29 +- 0.29 / 0.09 +- 0.02 / 440\n",
      "5 / 0.3 +- 0.31 / 0.05 +- 0.01 / 262\n",
      "6 / 0.26 +- 0.32 / 0.02 +- 0.0 / 167\n",
      "7 / 0.26 +- 0.3 / 0.01 +- 0.0 / 129\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_j_6B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 5329.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 29% / 3267\n",
      "0 / 0% / 80\n",
      "1 / 6% / 1013\n",
      "2 / 20% / 770\n",
      "3 / 35% / 519\n",
      "4 / 53% / 363\n",
      "5 / 63% / 237\n",
      "6 / 71% / 157\n",
      "7 / 71% / 128\n",
      "Failure cases\n",
      "total / 0.21 +- 0.24 / 0.38 +- 0.29 / 3267\n",
      "0 / 0.4 +- 0.31 / 1.0 +- 0.0 / 80\n",
      "1 / 0.24 +- 0.25 / 0.71 +- 0.14 / 1013\n",
      "2 / 0.23 +- 0.23 / 0.37 +- 0.07 / 770\n",
      "3 / 0.2 +- 0.23 / 0.18 +- 0.04 / 519\n",
      "4 / 0.16 +- 0.19 / 0.09 +- 0.02 / 363\n",
      "5 / 0.13 +- 0.18 / 0.05 +- 0.01 / 237\n",
      "6 / 0.13 +- 0.21 / 0.02 +- 0.0 / 157\n",
      "7 / 0.09 +- 0.2 / 0.01 +- 0.0 / 128\n",
      "==============================\n",
      "==============================\n",
      "Model: text-davinci-003\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 5593.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 34% / 1786\n",
      "0 / 0% / 135\n",
      "1 / 18% / 655\n",
      "2 / 41% / 473\n",
      "3 / 50% / 300\n",
      "4 / 64% / 130\n",
      "5 / 66% / 59\n",
      "6 / 80% / 25\n",
      "7 / 100% / 9\n",
      "Failure cases\n",
      "total / 0.35 +- 0.27 / 0.48 +- 0.3 / 1786\n",
      "0 / 0.4 +- 0.3 / 1.0 +- 0.0 / 135\n",
      "1 / 0.42 +- 0.28 / 0.72 +- 0.13 / 655\n",
      "2 / 0.35 +- 0.26 / 0.37 +- 0.07 / 473\n",
      "3 / 0.26 +- 0.23 / 0.19 +- 0.04 / 300\n",
      "4 / 0.24 +- 0.24 / 0.09 +- 0.02 / 130\n",
      "5 / 0.17 +- 0.21 / 0.05 +- 0.01 / 59\n",
      "6 / 0.11 +- 0.11 / 0.02 +- 0.0 / 25\n",
      "7 / 0.08 +- 0.07 / 0.01 +- 0.0 / 9\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt-3.5-turbo-0301\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 5514.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 26% / 1785\n",
      "0 / 0% / 127\n",
      "1 / 11% / 581\n",
      "2 / 28% / 464\n",
      "3 / 39% / 344\n",
      "4 / 45% / 153\n",
      "5 / 58% / 67\n",
      "6 / 62% / 35\n",
      "7 / 78% / 14\n",
      "Failure cases\n",
      "total / 0.23 +- 0.26 / 0.44 +- 0.3 / 1785\n",
      "0 / 0.32 +- 0.26 / 1.0 +- 0.0 / 127\n",
      "1 / 0.28 +- 0.3 / 0.71 +- 0.13 / 581\n",
      "2 / 0.23 +- 0.25 / 0.37 +- 0.07 / 464\n",
      "3 / 0.21 +- 0.23 / 0.18 +- 0.04 / 344\n",
      "4 / 0.16 +- 0.21 / 0.09 +- 0.02 / 153\n",
      "5 / 0.13 +- 0.17 / 0.05 +- 0.01 / 67\n",
      "6 / 0.08 +- 0.09 / 0.02 +- 0.0 / 35\n",
      "7 / 0.03 +- 0.03 / 0.01 +- 0.0 / 14\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt-4-0314\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 5371.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count in failure cases\n",
      "total / 28% / 1748\n",
      "0 / 0% / 121\n",
      "1 / 15% / 573\n",
      "2 / 25% / 468\n",
      "3 / 43% / 355\n",
      "4 / 52% / 136\n",
      "5 / 56% / 55\n",
      "6 / 80% / 26\n",
      "7 / 92% / 14\n",
      "Failure cases\n",
      "total / 0.26 +- 0.3 / 0.45 +- 0.3 / 1748\n",
      "0 / 0.33 +- 0.28 / 1.0 +- 0.0 / 121\n",
      "1 / 0.29 +- 0.33 / 0.72 +- 0.13 / 573\n",
      "2 / 0.26 +- 0.31 / 0.37 +- 0.07 / 468\n",
      "3 / 0.23 +- 0.26 / 0.19 +- 0.04 / 355\n",
      "4 / 0.26 +- 0.31 / 0.09 +- 0.02 / 136\n",
      "5 / 0.2 +- 0.25 / 0.05 +- 0.01 / 55\n",
      "6 / 0.17 +- 0.19 / 0.02 +- 0.0 / 26\n",
      "7 / 0.11 +- 0.19 / 0.01 +- 0.0 / 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['gpt_neo_125M', 'gpt_neo_125M_TREx', 'gpt_neo_1_3B', 'gpt_neo_1_3B_TREx',\n",
    "               'gpt_neo_2_7B', 'gpt_neo_2_7B_TREx', 'gpt_j_6B', 'gpt_j_6B_TREx']\n",
    "openai_model_names = ['text-davinci-003', 'gpt-3.5-turbo-0301', 'gpt-4-0314']\n",
    "\n",
    "num_sections = 8\n",
    "def prob_value_to_section(value):\n",
    "    return min(int(np.ceil(-np.log2(value+0.000001))), num_sections - 1)\n",
    "    \n",
    "for model_name in model_names + openai_model_names:\n",
    "    if model_name in openai_model_names:\n",
    "        pred_test_filename = \"../results/\" + model_name + \"/pred_possible_only.json\"\n",
    "    else:\n",
    "        pred_test_filename = \"../results/\" + model_name + \"/pred_factual_probing_test.json\"\n",
    "\n",
    "    print('='*30)\n",
    "    print('='*30)\n",
    "    print('Model:', model_name)\n",
    "    \n",
    "    with open(pred_test_filename, \"r\") as fin:\n",
    "        preds = json.load(fin)\n",
    "\n",
    "    print('Test')\n",
    "\n",
    "    condprob_gt_bin_total = defaultdict(list)\n",
    "    condprob_pred_bin_total = defaultdict(list)\n",
    "    condprob_gt_bin_success = defaultdict(list)\n",
    "    condprob_pred_bin_success = defaultdict(list)\n",
    "    condprob_gt_bin_failure = defaultdict(list)\n",
    "    condprob_pred_bin_failure = defaultdict(list)\n",
    "\n",
    "    count_bin_failure = defaultdict(list)\n",
    "\n",
    "    for pred in tqdm(preds):\n",
    "        subj = uid_subj_map[pred['uid']]\n",
    "        rel = uid_rel_map[pred['uid']]\n",
    "        label_text = pred['label_text'].lower()\n",
    "        rel_subj_object = deepcopy(rel_subj_objects[rel+'_'+subj])\n",
    "        rel_subj_object.remove(label_text)\n",
    "\n",
    "        if model_name in openai_model_names:\n",
    "            pred_top_1_remove_stopwords = pred['top_1_text_remove_stopwords']\n",
    "        else:\n",
    "            # we remove other valid objects for a subject-relation pair other than the one we test\n",
    "            for w in pred['top_100_text_remove_stopwords']:\n",
    "                w = w.lower().strip()\n",
    "                if w not in rel_subj_object or True:\n",
    "                    pred_top_1_remove_stopwords = w\n",
    "                    break\n",
    "\n",
    "        subj = ' '.join(text_normalization_without_lemmatization(subj))\n",
    "        obj_gt = ' '.join(text_normalization_without_lemmatization(label_text))\n",
    "        obj_pred = ' '.join(text_normalization_without_lemmatization(pred_top_1_remove_stopwords))\n",
    "        joint_freq_gt = coo_matrix.coo_count(subj, obj_gt)\n",
    "        joint_freq_pred = coo_matrix.coo_count(subj, obj_pred)\n",
    "        # skip if the entities are composed of more than 3 tokens, or are stopwords\n",
    "        if joint_freq_gt <= 0 or joint_freq_pred <= 0:\n",
    "            continue\n",
    "        subj_freq = coo_matrix.count(subj)\n",
    "        cond_prob_gt = joint_freq_gt / subj_freq if subj_freq > 0 else 0\n",
    "        cond_prob_pred = joint_freq_pred / subj_freq if subj_freq > 0 else 0\n",
    "\n",
    "        bin = prob_value_to_section(cond_prob_gt)\n",
    "\n",
    "        condprob_gt_bin_total[bin].append(cond_prob_gt)\n",
    "        condprob_pred_bin_total[bin].append(cond_prob_pred)\n",
    "        condprob_gt_bin_total['total'].append(cond_prob_gt)\n",
    "        condprob_pred_bin_total['total'].append(cond_prob_pred)\n",
    "        if pred['hits@1_remove_stopwords'] > 0.5:\n",
    "            condprob_gt_bin_success[bin].append(cond_prob_gt)\n",
    "            condprob_pred_bin_success[bin].append(cond_prob_pred)\n",
    "            condprob_gt_bin_success['total'].append(cond_prob_gt)\n",
    "            condprob_pred_bin_success['total'].append(cond_prob_pred)\n",
    "        else:\n",
    "            condprob_gt_bin_failure[bin].append(cond_prob_gt)\n",
    "            condprob_pred_bin_failure[bin].append(cond_prob_pred)\n",
    "            condprob_gt_bin_failure['total'].append(cond_prob_gt)\n",
    "            condprob_pred_bin_failure['total'].append(cond_prob_pred)\n",
    "            count_bin_failure[bin].append((cond_prob_pred > cond_prob_gt)*1)\n",
    "            count_bin_failure['total'].append((cond_prob_pred > cond_prob_gt)*1)\n",
    "\n",
    "    # print('Total')\n",
    "    # for bin in ['total'] + list(range(num_sections)):\n",
    "    #     print(f\"{bin} / {round(np.mean(condprob_pred_bin_total[bin]), 2)} +- {round(np.std(condprob_pred_bin_total[bin]), 2) } / {round(np.mean(condprob_gt_bin_total[bin]), 2)} +- {round(np.std(condprob_gt_bin_total[bin]), 2)} / {len(condprob_pred_bin_total[bin])}\")\n",
    "    print('Count in failure cases')\n",
    "    for bin in ['total'] + list(range(num_sections)):\n",
    "        print(f\"{bin} / {int(np.mean(count_bin_failure[bin])*100)}% / {len(count_bin_failure[bin])}\")\n",
    "    print('Failure cases')\n",
    "    for bin in ['total'] + list(range(num_sections)):\n",
    "        print(f\"{bin} / {round(np.mean(condprob_pred_bin_failure[bin]), 2)} +- {round(np.std(condprob_pred_bin_failure[bin]), 2) } / {round(np.mean(condprob_gt_bin_failure[bin]), 2)} +- {round(np.std(condprob_gt_bin_failure[bin]), 2)} / {len(condprob_gt_bin_failure[bin])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooccurrence_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7a4e9927d9b69c1ba4cb0a31a5bbb5e48400df3d5cf589b0cc5b02ec19a25a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
