{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/cwkang/anaconda3/envs/cooccurrence_bias/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from cooccurrence_matrix import CooccurrenceMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coo_matrix = CooccurrenceMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "\n",
    "filter = {}\n",
    "for w in stopword_list:\n",
    "    filter[w] = w\n",
    "punctuations = {\n",
    "    \"?\": \"?\",\n",
    "    \":\": \":\",\n",
    "    \"!\": \"!\",\n",
    "    \".\": \".\",\n",
    "    \",\": \",\",\n",
    "    \";\": \";\"\n",
    "}\n",
    "filter.update(punctuations)\n",
    "def filtering(text):\n",
    "    if text in filter:\n",
    "        return True\n",
    "\n",
    "def text_normalization_without_lemmatization(text):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    for token in tokens:\n",
    "        token_low = token.lower()\n",
    "        if filtering(token_low):\n",
    "            continue\n",
    "        result.append(token_low)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/LAMA_TREx/all.json\", 'r') as fin:\n",
    "    f_all = json.load(fin)\n",
    "\n",
    "uid_rel_map = {}\n",
    "uid_subj_map = {}\n",
    "rel_subj_objects = defaultdict(set)\n",
    "for example in f_all:\n",
    "    subj = example['subj']\n",
    "    rel = example['rel_id']\n",
    "    obj = example['output']\n",
    "\n",
    "    uid_subj_map[example['uid']] = subj\n",
    "    uid_rel_map[example['uid']] = rel\n",
    "    rel_subj_objects[rel+'_'+subj].add(obj.lower())\n",
    "for key in rel_subj_objects:\n",
    "    rel_subj_objects[key] = list(rel_subj_objects[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_125M\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7439.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22 / -0.2 / 0.01 /// 1.1397398619484083e-93 / 2.775762805404166e-76 / 0.4370290297062604\n",
      "0.23 / -0.23 / 0.01 /// 4.977877270809893e-104 / 1.0239910559297291e-96 / 0.40498484681004615\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_125M_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7418.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 / -0.35 / -0.01 /// 2.1955324688252254e-238 / 7.945094184582398e-245 / 0.5823302815066153\n",
      "0.38 / -0.41 / -0.01 /// 1.565625273172974e-288 / 0.0 / 0.4396947470969913\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_1_3B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7442.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21 / -0.21 / 0.02 /// 2.4716382325051189e-85 / 2.2312264792659015e-80 / 0.16455429009143466\n",
      "0.26 / -0.26 / 0.01 /// 3.722179165546501e-126 / 7.996857678860146e-124 / 0.21534224411649433\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_1_3B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7394.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 / -0.36 / -0.01 /// 9.112245426681854e-234 / 2.898140799098851e-250 / 0.25400566699525146\n",
      "0.4 / -0.43 / -0.01 /// 2.5726e-319 / 0.0 / 0.1915752302154333\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_2_7B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7451.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21 / -0.21 / -0.02 /// 3.3737819012337525e-84 / 4.720919317879833e-80 / 0.11379673090262642\n",
      "0.26 / -0.26 / -0.02 /// 6.692195336818876e-132 / 3.826945925784204e-128 / 0.0802481979571421\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_neo_2_7B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7457.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 / -0.36 / 0.01 /// 9.029723248441689e-238 / 1.23232041575901e-254 / 0.28339167242622504\n",
      "0.4 / -0.43 / 0.02 /// 1.1364e-320 / 0.0 / 0.16751144351006717\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_j_6B\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7404.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24 / -0.24 / -0.01 /// 4.3241639482454355e-107 / 4.182139153425179e-106 / 0.6406932401649517\n",
      "0.29 / -0.29 / -0.01 /// 5.357333939435433e-164 / 9.505979065991612e-166 / 0.5323561992988697\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt_j_6B_TREx\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8856/8856 [00:01<00:00, 7323.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35 / -0.36 / -0.02 /// 4.320316945232727e-232 / 3.618007885726267e-254 / 0.05945469068305892\n",
      "0.4 / -0.43 / -0.01 /// 9.012e-320 / 0.0 / 0.26012075414909097\n",
      "==============================\n",
      "==============================\n",
      "Model: text-davinci-003\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 7414.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 / -0.23 / 0.01 /// 2.18628861601269e-56 / 1.0324329451855343e-45 / 0.5601093281775997\n",
      "0.25 / -0.23 / 0.01 /// 2.18628861601269e-56 / 1.0324329451855343e-45 / 0.5601093281775997\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt-3.5-turbo-0301\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 7096.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21 / -0.21 / -0.02 /// 6.569170608324027e-41 / 3.482007750886441e-38 / 0.19354403512890325\n",
      "0.21 / -0.21 / -0.02 /// 6.569170608324027e-41 / 3.482007750886441e-38 / 0.19354403512890325\n",
      "==============================\n",
      "==============================\n",
      "Model: gpt-4-0314\n",
      "Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4149/4149 [00:00<00:00, 7211.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22 / -0.2 / -0.01 /// 1.1353469735347542e-43 / 2.2795861983220642e-37 / 0.4532476412737201\n",
      "0.22 / -0.2 / -0.01 /// 1.1353469735347542e-43 / 2.2795861983220642e-37 / 0.4532476412737201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['gpt_neo_125M', 'gpt_neo_125M_TREx', 'gpt_neo_1_3B', 'gpt_neo_1_3B_TREx',\n",
    "               'gpt_neo_2_7B', 'gpt_neo_2_7B_TREx', 'gpt_j_6B', 'gpt_j_6B_TREx']\n",
    "openai_model_names = ['text-davinci-003', 'gpt-3.5-turbo-0301', 'gpt-4-0314']\n",
    "\n",
    "num_sections = 8\n",
    "def prob_value_to_section(value):\n",
    "    return min(int(np.ceil(-np.log2(value+0.000001))), num_sections - 1)\n",
    "    \n",
    "for model_name in model_names + openai_model_names:\n",
    "    if model_name in openai_model_names:\n",
    "        pred_test_filename = \"../results/\" + model_name + \"/pred_possible_only.json\"\n",
    "    else:\n",
    "        pred_test_filename = \"../results/\" + model_name + \"/pred_factual_probing_test.json\"\n",
    "\n",
    "    print('='*30)\n",
    "    print('='*30)\n",
    "    print('Model:', model_name)\n",
    "    \n",
    "    with open(pred_test_filename, \"r\") as fin:\n",
    "        preds = json.load(fin)\n",
    "\n",
    "    print('Test')\n",
    "\n",
    "    hits_1 = []\n",
    "    mrr = []\n",
    "    cond_probs = []\n",
    "    bins = []\n",
    "\n",
    "    for pred in tqdm(preds):\n",
    "        subj = uid_subj_map[pred['uid']]\n",
    "        rel = uid_rel_map[pred['uid']]\n",
    "        label_text = pred['label_text'].lower()\n",
    "        rel_subj_object = deepcopy(rel_subj_objects[rel+'_'+subj])\n",
    "        rel_subj_object.remove(label_text)\n",
    "\n",
    "        subj = ' '.join(text_normalization_without_lemmatization(subj))\n",
    "        obj_gt = ' '.join(text_normalization_without_lemmatization(label_text))\n",
    "        joint_freq_gt = coo_matrix.coo_count(subj, obj_gt)\n",
    "        # skip if the entities are composed of more than 3 tokens, or are stopwords\n",
    "        if joint_freq_gt <= 0:\n",
    "            continue\n",
    "        subj_freq = coo_matrix.count(subj)\n",
    "        cond_prob_gt = joint_freq_gt / subj_freq if subj_freq > 0 else 0\n",
    "\n",
    "        bin = prob_value_to_section(cond_prob_gt)\n",
    "\n",
    "        hits_1.append(pred['hits@1_remove_stopwords'])\n",
    "        if 'mrr_remove_stopwords' in pred:\n",
    "            mrr.append(pred['mrr_remove_stopwords'])\n",
    "        else:\n",
    "            mrr.append(pred['hits@1_remove_stopwords'])\n",
    "        cond_probs.append(cond_prob_gt)\n",
    "        bins.append(bin)\n",
    "\n",
    "    without_binning = stats.pearsonr(hits_1, cond_probs)\n",
    "    with_binning = stats.pearsonr(hits_1, bins)\n",
    "    mrr_without_binning = stats.pearsonr(mrr, cond_probs)\n",
    "    mrr_with_binning = stats.pearsonr(mrr, bins)\n",
    "    rand_cond_probs = deepcopy(cond_probs)\n",
    "    random.shuffle(rand_cond_probs)\n",
    "    without_binning_random = stats.pearsonr(hits_1, rand_cond_probs)\n",
    "    mrr_without_binning_random = stats.pearsonr(mrr, rand_cond_probs)\n",
    "    print(f\"{round(without_binning.statistic, 2)} / {round(with_binning.statistic, 2)} / {round(without_binning_random.statistic, 2)} /// {without_binning.pvalue} / {with_binning.pvalue} / {without_binning_random.pvalue}\")\n",
    "    print(f\"{round(mrr_without_binning.statistic, 2)} / {round(mrr_with_binning.statistic, 2)} / {round(mrr_without_binning_random.statistic, 2)} /// {mrr_without_binning.pvalue} / {mrr_with_binning.pvalue} / {mrr_without_binning_random.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cooccurrence_bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7a4e9927d9b69c1ba4cb0a31a5bbb5e48400df3d5cf589b0cc5b02ec19a25a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
