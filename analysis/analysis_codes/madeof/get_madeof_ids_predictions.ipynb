{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../../../data/ConceptNet/test.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/161169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161169/161169 [00:00<00:00, 1835602.38it/s]\n"
     ]
    }
   ],
   "source": [
    "uid_example_map = {}\n",
    "for example in tqdm(data):\n",
    "    uid_example_map[example['uid']] = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('madeof_ids.json', 'r') as fin:\n",
    "    valid_ids = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'bert-base-uncased', 'bert-large-uncased',\n",
    "    'roberta-base', 'roberta-large',\n",
    "    'albert-base-v1', 'albert-large-v1', 'albert-xlarge-v1',\n",
    "    'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2',\n",
    "    'gpt-neo-125m', 'gpt-neo-1.3B', 'gpt-neo-2.7B', 'gpt-j-6b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased 98\n",
      "bert-large-uncased 98\n",
      "roberta-base 98\n",
      "roberta-large 98\n",
      "albert-base-v1 98\n",
      "albert-large-v1 98\n",
      "albert-xlarge-v1 98\n",
      "albert-base-v2 98\n",
      "albert-large-v2 98\n",
      "albert-xlarge-v2 98\n",
      "gpt-neo-125m 98\n",
      "gpt-neo-1.3B 98\n",
      "gpt-neo-2.7B 98\n",
      "gpt-j-6b 98\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    model_path = os.path.join('../../../results/ConceptNet', model_name+'_ConceptNet_zeroshot')\n",
    "    pred_path = os.path.join(model_path, 'pred_ConceptNet_test.jsonl')\n",
    "    \n",
    "    with jsonlines.open(pred_path) as fin:\n",
    "        results = []\n",
    "        \n",
    "        for line in fin.iter():\n",
    "            uid = line['uid']\n",
    "\n",
    "            if uid not in valid_ids:\n",
    "                continue\n",
    "\n",
    "            subj = uid_example_map[uid]['subj']\n",
    "            rel_id = uid_example_map[uid]['rel_id']\n",
    "            label_text = line['label_text']\n",
    "            top_100_text = line['top_100_text_remove_stopwords']\n",
    "            mrr = line['mrr_remove_stopwords']\n",
    "            hits_1 = line['hits@1_remove_stopwords']\n",
    "            hits_10 = line['hits@10_remove_stopwords']\n",
    "            hits_100 = line['hits@100_remove_stopwords']\n",
    "            result = {\n",
    "                'uid': uid,\n",
    "                'subj': subj,\n",
    "                'rel_id': rel_id,\n",
    "                'label_text': label_text,\n",
    "                'top_100_text': top_100_text,\n",
    "                'mrr': mrr,\n",
    "                'hits@1': hits_1,\n",
    "                'hits@10': hits_10,\n",
    "                'hits@100': hits_100,\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    out_path = os.path.join('results', model_name+'_madeof_predictions.jsonl')\n",
    "    with open(out_path, 'w') as fout:\n",
    "        print(model_name, len(results))\n",
    "        for result in results:\n",
    "            json.dump(result, fout)\n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'gpt-3.5-turbo-0125', 'gpt-4-0125-preview'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125 52\n",
      "gpt-4-0125-preview 52\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    model_path = os.path.join('../../../results/ConceptNet', model_name+'_ConceptNet_zeroshot')\n",
    "    pred_path = os.path.join(model_path, 'pred_ConceptNet_test.jsonl')\n",
    "    \n",
    "    with jsonlines.open(pred_path) as fin:\n",
    "        results = []\n",
    "        \n",
    "        for line in fin.iter():\n",
    "            uid = line['uid']\n",
    "\n",
    "            if uid not in valid_ids:\n",
    "                continue\n",
    "\n",
    "            subj = uid_example_map[uid]['subj']\n",
    "            rel_id = uid_example_map[uid]['rel_id']\n",
    "            label_text = line['label_text']\n",
    "            top_5_text = line['top_5_text_remove_stopwords']\n",
    "            hits_1 = line['hits@1_remove_stopwords']\n",
    "            result = {\n",
    "                'uid': uid,\n",
    "                'subj': subj,\n",
    "                'rel_id': rel_id,\n",
    "                'label_text': label_text,\n",
    "                'top_5_text': top_5_text,\n",
    "                'hits@1': hits_1,\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    out_path = os.path.join('results', model_name+'_madeof_predictions.jsonl')\n",
    "    with open(out_path, 'w') as fout:\n",
    "        print(model_name, len(results))\n",
    "        for result in results:\n",
    "            json.dump(result, fout)\n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    'bert-base-uncased', 'bert-large-uncased',\n",
    "    'gpt-neo-125m','gpt-j-6b',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased 98\n",
      "bert-large-uncased 98\n",
      "gpt-neo-125m 98\n",
      "gpt-j-6b 98\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    model_path = os.path.join('../../../results/ConceptNet', model_name+'_ConceptNet_prompt_tuning')\n",
    "    pred_path = os.path.join(model_path, 'pred_ConceptNet_test.jsonl')\n",
    "    \n",
    "    with jsonlines.open(pred_path) as fin:\n",
    "        results = []\n",
    "        \n",
    "        for line in fin.iter():\n",
    "            uid = line['uid']\n",
    "\n",
    "            if uid not in valid_ids:\n",
    "                continue\n",
    "\n",
    "            subj = uid_example_map[uid]['subj']\n",
    "            rel_id = uid_example_map[uid]['rel_id']\n",
    "            label_text = line['label_text']\n",
    "            top_100_text = line['top_100_text_remove_stopwords']\n",
    "            mrr = line['mrr_remove_stopwords']\n",
    "            hits_1 = line['hits@1_remove_stopwords']\n",
    "            hits_10 = line['hits@10_remove_stopwords']\n",
    "            hits_100 = line['hits@100_remove_stopwords']\n",
    "            result = {\n",
    "                'uid': uid,\n",
    "                'subj': subj,\n",
    "                'rel_id': rel_id,\n",
    "                'label_text': label_text,\n",
    "                'top_100_text': top_100_text,\n",
    "                'mrr': mrr,\n",
    "                'hits@1': hits_1,\n",
    "                'hits@10': hits_10,\n",
    "                'hits@100': hits_100,\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "    out_path = os.path.join('results', model_name+'_prompt_tuning_madeof_predictions.jsonl')\n",
    "    with open(out_path, 'w') as fout:\n",
    "        print(model_name, len(results))\n",
    "        for result in results:\n",
    "            json.dump(result, fout)\n",
    "            fout.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factual_knowledge_probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
