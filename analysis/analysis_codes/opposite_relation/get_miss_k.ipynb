{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_answers = json.load(open('synonym_answers.json', 'r'))\n",
    "antonym_answers = json.load(open('antonym_answers.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict = {\n",
    "    'bert-base-uncased': 'BERT$_{base}$',\n",
    "    'bert-large-uncased': 'BERT$_{large}$',\n",
    "    'albert-base-v1': 'ALBERT1$_{base}$',\n",
    "    'albert-large-v1': 'ALBERT1$_{large}$',\n",
    "    'albert-xlarge-v1': 'ALBERT1$_{xlarge}$',\n",
    "    'albert-base-v2': 'ALBERT2$_{base}$',\n",
    "    'albert-large-v2': 'ALBERT2$_{large}$',\n",
    "    'albert-xlarge-v2': 'ALBERT2$_{xlarge}$',\n",
    "    'roberta-base': 'RoBERTa$_{base}$',\n",
    "    'roberta-large': 'RoBERTa$_{large}$',\n",
    "    'gpt-neo-125m': 'GPT-Neo 125M',\n",
    "    'gpt-neo-1.3B': 'GPT-Neo 1.3B',\n",
    "    'gpt-neo-2.7B': 'GPT-Neo 2.7B',\n",
    "    'gpt-j-6b': 'GPT-J 6B',\n",
    "    # 'gpt-3.5-turbo-0125': 'ChatGPT-3.5',\n",
    "    # 'gpt-4-0125-preview': 'ChatGPT-4'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_lower(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(word.lower().strip())\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& BERT$_{base}$ & 0.07$\\pm$0.26 & 0.23$\\pm$0.42 & 0.42$\\pm$0.49 & 0.21$\\pm$0.41 & 0.33$\\pm$0.47 & 0.44$\\pm$0.50\\\\\n",
      "& BERT$_{large}$ & 0.10$\\pm$0.29 & 0.26$\\pm$0.44 & 0.48$\\pm$0.50 & 0.13$\\pm$0.34 & 0.34$\\pm$0.47 & 0.52$\\pm$0.50\\\\\n",
      "& ALBERT1$_{base}$ & 0.01$\\pm$0.08 & 0.21$\\pm$0.41 & 0.42$\\pm$0.49 & 0.26$\\pm$0.44 & 0.34$\\pm$0.47 & 0.45$\\pm$0.50\\\\\n",
      "& ALBERT1$_{large}$ & 0.01$\\pm$0.12 & 0.12$\\pm$0.32 & 0.30$\\pm$0.46 & 0.22$\\pm$0.42 & 0.30$\\pm$0.46 & 0.39$\\pm$0.49\\\\\n",
      "& ALBERT1$_{xlarge}$ & 0.03$\\pm$0.17 & 0.21$\\pm$0.40 & 0.39$\\pm$0.49 & 0.23$\\pm$0.42 & 0.36$\\pm$0.48 & 0.53$\\pm$0.50\\\\\n",
      "& ALBERT2$_{base}$ & 0.04$\\pm$0.19 & 0.20$\\pm$0.40 & 0.40$\\pm$0.49 & 0.16$\\pm$0.37 & 0.35$\\pm$0.48 & 0.50$\\pm$0.50\\\\\n",
      "& ALBERT2$_{large}$ & 0.08$\\pm$0.26 & 0.32$\\pm$0.47 & 0.56$\\pm$0.50 & 0.21$\\pm$0.41 & 0.38$\\pm$0.49 & 0.56$\\pm$0.50\\\\\n",
      "& ALBERT2$_{xlarge}$ & 0.09$\\pm$0.29 & 0.27$\\pm$0.44 & 0.50$\\pm$0.50 & 0.12$\\pm$0.32 & 0.34$\\pm$0.47 & 0.59$\\pm$0.49\\\\\n",
      "& RoBERTa$_{base}$ & 0.01$\\pm$0.09 & 0.02$\\pm$0.15 & 0.06$\\pm$0.25 & 0.00$\\pm$0.07 & 0.02$\\pm$0.15 & 0.08$\\pm$0.27\\\\\n",
      "& RoBERTa$_{large}$ & 0.01$\\pm$0.11 & 0.04$\\pm$0.20 & 0.08$\\pm$0.26 & 0.01$\\pm$0.08 & 0.03$\\pm$0.16 & 0.08$\\pm$0.27\\\\\n",
      "& GPT-Neo 125M & 0.00$\\pm$0.06 & 0.02$\\pm$0.15 & 0.12$\\pm$0.33 & 0.01$\\pm$0.09 & 0.04$\\pm$0.19 & 0.19$\\pm$0.39\\\\\n",
      "& GPT-Neo 1.3B & 0.03$\\pm$0.16 & 0.10$\\pm$0.31 & 0.28$\\pm$0.45 & 0.05$\\pm$0.23 & 0.15$\\pm$0.35 & 0.37$\\pm$0.48\\\\\n",
      "& GPT-Neo 2.7B & 0.03$\\pm$0.17 & 0.13$\\pm$0.33 & 0.31$\\pm$0.46 & 0.06$\\pm$0.24 & 0.22$\\pm$0.41 & 0.44$\\pm$0.50\\\\\n",
      "& GPT-J 6B & 0.04$\\pm$0.19 & 0.16$\\pm$0.37 & 0.37$\\pm$0.48 & 0.04$\\pm$0.20 & 0.20$\\pm$0.40 & 0.43$\\pm$0.50\\\\\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_name_dict.keys():\n",
    "    try:\n",
    "        data = jsonlines.open(f'results/{model_name}_opposite_relation_predictions.jsonl')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    synonym_examples, antonym_examples = {}, {}\n",
    "\n",
    "    for example in data.iter():\n",
    "        if example['rel_id'] == 'Synonym':\n",
    "            synonym_examples[example['subj']] = example\n",
    "        elif example['rel_id'] == 'Antonym':\n",
    "            antonym_examples[example['subj']] = example\n",
    "\n",
    "    overlap_k_list = defaultdict(list)\n",
    "    miss_k_synonym_list = defaultdict(list)\n",
    "    miss_k_antonym_list = defaultdict(list)\n",
    "\n",
    "    for example in synonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_100_text'])\n",
    "        if example['subj'] in antonym_examples:\n",
    "            top_100_words_opposite = strip_lower(antonym_examples[example['subj']]['top_100_text'])\n",
    "\n",
    "            for k in [1, 10, 100]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1, 10, 100]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = antonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_synonym_list[k].append(miss_k)\n",
    "\n",
    "    for example in antonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_100_text'])\n",
    "        if example['subj'] in synonym_examples:\n",
    "            top_100_words_opposite = strip_lower(synonym_examples[example['subj']]['top_100_text'])\n",
    "\n",
    "            for k in [1, 10, 100]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1, 10, 100]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = synonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_antonym_list[k].append(miss_k)\n",
    "\n",
    "    # print(f'{model_name} - len_overlap_k: {len(overlap_k_list[1])}, len_miss_k_synonym: {len(miss_k_synonym_list[1])}, len_miss_k_antonym: {len(miss_k_antonym_list[1])}')\n",
    "\n",
    "    miss_1_synonym, miss_10_synonym, miss_100_synonym = miss_k_synonym_list[1], miss_k_synonym_list[10], miss_k_synonym_list[100]\n",
    "    average_miss_1_synonym = f'{np.mean(miss_1_synonym):.2f} +- {np.std(miss_1_synonym):.2f}'.split('+-')\n",
    "    average_miss_10_synonym = f'{np.mean(miss_10_synonym):.2f} +- {np.std(miss_10_synonym):.2f}'.split('+-')\n",
    "    average_miss_100_synonym = f'{np.mean(miss_100_synonym):.2f} +- {np.std(miss_100_synonym):.2f}'.split('+-')\n",
    "\n",
    "    miss_1_antonym, miss_10_antonym, miss_100_antonym = miss_k_antonym_list[1], miss_k_antonym_list[10], miss_k_antonym_list[100]\n",
    "    average_miss_1_antonym = f'{np.mean(miss_1_antonym):.2f} +- {np.std(miss_1_antonym):.2f}'.split('+-')\n",
    "    average_miss_10_antonym = f'{np.mean(miss_10_antonym):.2f} +- {np.std(miss_10_antonym):.2f}'.split('+-')\n",
    "    average_miss_100_antonym = f'{np.mean(miss_100_antonym):.2f} +- {np.std(miss_100_antonym):.2f}'.split('+-')\n",
    "\n",
    "    line = f'& {model_name_dict[model_name]} ' + \\\n",
    "    f'& {average_miss_1_synonym[0].strip()}$\\pm${average_miss_1_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_synonym[0].strip()}$\\pm${average_miss_10_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_synonym[0].strip()}$\\pm${average_miss_100_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_1_antonym[0].strip()}$\\pm${average_miss_1_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_antonym[0].strip()}$\\pm${average_miss_10_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_antonym[0].strip()}$\\pm${average_miss_100_antonym[1].strip()}\\\\\\\\'\n",
    "\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& BERT$_{base}$ & 0.02$\\pm$0.13 & 0.31$\\pm$0.46 & 0.59$\\pm$0.49 & 0.17$\\pm$0.37 & 0.40$\\pm$0.49 & 0.63$\\pm$0.48\\\\\n",
      "& BERT$_{large}$ & 0.02$\\pm$0.14 & 0.28$\\pm$0.45 & 0.60$\\pm$0.49 & 0.14$\\pm$0.34 & 0.40$\\pm$0.49 & 0.65$\\pm$0.48\\\\\n",
      "& GPT-Neo 125M & 0.00$\\pm$0.00 & 0.00$\\pm$0.04 & 0.02$\\pm$0.14 & 0.00$\\pm$0.00 & 0.00$\\pm$0.04 & 0.02$\\pm$0.12\\\\\n",
      "& GPT-J 6B & 0.01$\\pm$0.09 & 0.13$\\pm$0.33 & 0.47$\\pm$0.50 & 0.01$\\pm$0.12 & 0.19$\\pm$0.39 & 0.56$\\pm$0.50\\\\\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_name_dict.keys():\n",
    "    try:\n",
    "        data = jsonlines.open(f'results/{model_name}_prompt_tuning_opposite_relation_predictions.jsonl')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    synonym_examples, antonym_examples = {}, {}\n",
    "\n",
    "    for example in data.iter():\n",
    "        if example['rel_id'] == 'Synonym':\n",
    "            synonym_examples[example['subj']] = example\n",
    "        elif example['rel_id'] == 'Antonym':\n",
    "            antonym_examples[example['subj']] = example\n",
    "\n",
    "    overlap_k_list = defaultdict(list)\n",
    "    miss_k_synonym_list = defaultdict(list)\n",
    "    miss_k_antonym_list = defaultdict(list)\n",
    "\n",
    "    for example in synonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_100_text'])\n",
    "        if example['subj'] in antonym_examples:\n",
    "            top_100_words_opposite = strip_lower(antonym_examples[example['subj']]['top_100_text'])\n",
    "\n",
    "            for k in [1, 10, 100]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1, 10, 100]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = antonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_synonym_list[k].append(miss_k)\n",
    "\n",
    "    for example in antonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_100_text'])\n",
    "        if example['subj'] in synonym_examples:\n",
    "            top_100_words_opposite = strip_lower(synonym_examples[example['subj']]['top_100_text'])\n",
    "\n",
    "            for k in [1, 10, 100]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1, 10, 100]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = synonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_antonym_list[k].append(miss_k)\n",
    "\n",
    "    # print(f'{model_name} - len_overlap_k: {len(overlap_k_list[1])}, len_miss_k_synonym: {len(miss_k_synonym_list[1])}, len_miss_k_antonym: {len(miss_k_antonym_list[1])}')\n",
    "\n",
    "    miss_1_synonym, miss_10_synonym, miss_100_synonym = miss_k_synonym_list[1], miss_k_synonym_list[10], miss_k_synonym_list[100]\n",
    "    average_miss_1_synonym = f'{np.mean(miss_1_synonym):.2f} +- {np.std(miss_1_synonym):.2f}'.split('+-')\n",
    "    average_miss_10_synonym = f'{np.mean(miss_10_synonym):.2f} +- {np.std(miss_10_synonym):.2f}'.split('+-')\n",
    "    average_miss_100_synonym = f'{np.mean(miss_100_synonym):.2f} +- {np.std(miss_100_synonym):.2f}'.split('+-')\n",
    "\n",
    "    miss_1_antonym, miss_10_antonym, miss_100_antonym = miss_k_antonym_list[1], miss_k_antonym_list[10], miss_k_antonym_list[100]\n",
    "    average_miss_1_antonym = f'{np.mean(miss_1_antonym):.2f} +- {np.std(miss_1_antonym):.2f}'.split('+-')\n",
    "    average_miss_10_antonym = f'{np.mean(miss_10_antonym):.2f} +- {np.std(miss_10_antonym):.2f}'.split('+-')\n",
    "    average_miss_100_antonym = f'{np.mean(miss_100_antonym):.2f} +- {np.std(miss_100_antonym):.2f}'.split('+-')\n",
    "\n",
    "    line = f'& {model_name_dict[model_name]} ' + \\\n",
    "    f'& {average_miss_1_synonym[0].strip()}$\\pm${average_miss_1_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_synonym[0].strip()}$\\pm${average_miss_10_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_synonym[0].strip()}$\\pm${average_miss_100_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_1_antonym[0].strip()}$\\pm${average_miss_1_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_antonym[0].strip()}$\\pm${average_miss_10_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_antonym[0].strip()}$\\pm${average_miss_100_antonym[1].strip()}\\\\\\\\'\n",
    "\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict = {\n",
    "    'gpt-3.5-turbo-0125': 'ChatGPT-3.5',\n",
    "    'gpt-4-0125-preview': 'ChatGPT-4'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& ChatGPT-3.5 & 0.02$\\pm$0.12 & nan$\\pm$nan & nan$\\pm$nan & 0.01$\\pm$0.09 & nan$\\pm$nan & nan$\\pm$nan\\\\\n",
      "& ChatGPT-4 & 0.00$\\pm$0.00 & nan$\\pm$nan & nan$\\pm$nan & 0.09$\\pm$0.29 & nan$\\pm$nan & nan$\\pm$nan\\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/numpy/core/_methods.py:269: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/home/cheongwoong/miniconda3/envs/factual_knowledge_probing/lib/python3.9/site-packages/numpy/core/_methods.py:261: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_name_dict.keys():\n",
    "    try:\n",
    "        data = jsonlines.open(f'results/{model_name}_opposite_relation_predictions.jsonl')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    synonym_examples, antonym_examples = {}, {}\n",
    "\n",
    "    for example in data.iter():\n",
    "        if example['rel_id'] == 'Synonym':\n",
    "            synonym_examples[example['subj']] = example\n",
    "        elif example['rel_id'] == 'Antonym':\n",
    "            antonym_examples[example['subj']] = example\n",
    "\n",
    "    overlap_k_list = defaultdict(list)\n",
    "    miss_k_synonym_list = defaultdict(list)\n",
    "    miss_k_antonym_list = defaultdict(list)\n",
    "\n",
    "    for example in synonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_5_text'])\n",
    "        if example['subj'] in antonym_examples:\n",
    "            top_100_words_opposite = strip_lower(antonym_examples[example['subj']]['top_5_text'])\n",
    "\n",
    "            for k in [1]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = antonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_synonym_list[k].append(miss_k)\n",
    "\n",
    "    for example in antonym_examples.values():\n",
    "        top_100_words = strip_lower(example['top_5_text'])\n",
    "        if example['subj'] in synonym_examples:\n",
    "            top_100_words_opposite = strip_lower(synonym_examples[example['subj']]['top_5_text'])\n",
    "\n",
    "            for k in [1]:\n",
    "                top_k_words = top_100_words[:k]\n",
    "                top_k_words_opposite = top_100_words_opposite[:k]\n",
    "\n",
    "                overlap_k = len(set(top_k_words) & set(top_k_words_opposite)) / k\n",
    "                overlap_k_list[k].append(overlap_k)\n",
    "\n",
    "        for k in [1]:\n",
    "            top_k_words = top_100_words[:k]\n",
    "            gold_objects_opposite = synonym_answers[example['subj']]\n",
    "\n",
    "            miss_k = len(set(top_k_words) & set(gold_objects_opposite)) / len(set(gold_objects_opposite))\n",
    "            miss_k_antonym_list[k].append(miss_k)\n",
    "\n",
    "    # print(f'{model_name} - len_overlap_k: {len(overlap_k_list[1])}, len_miss_k_synonym: {len(miss_k_synonym_list[1])}, len_miss_k_antonym: {len(miss_k_antonym_list[1])}')\n",
    "\n",
    "    miss_1_synonym, miss_10_synonym, miss_100_synonym = miss_k_synonym_list[1], miss_k_synonym_list[10], miss_k_synonym_list[100]\n",
    "    average_miss_1_synonym = f'{np.mean(miss_1_synonym):.2f} +- {np.std(miss_1_synonym):.2f}'.split('+-')\n",
    "    average_miss_10_synonym = f'{np.mean(miss_10_synonym):.2f} +- {np.std(miss_10_synonym):.2f}'.split('+-')\n",
    "    average_miss_100_synonym = f'{np.mean(miss_100_synonym):.2f} +- {np.std(miss_100_synonym):.2f}'.split('+-')\n",
    "\n",
    "    miss_1_antonym, miss_10_antonym, miss_100_antonym = miss_k_antonym_list[1], miss_k_antonym_list[10], miss_k_antonym_list[100]\n",
    "    average_miss_1_antonym = f'{np.mean(miss_1_antonym):.2f} +- {np.std(miss_1_antonym):.2f}'.split('+-')\n",
    "    average_miss_10_antonym = f'{np.mean(miss_10_antonym):.2f} +- {np.std(miss_10_antonym):.2f}'.split('+-')\n",
    "    average_miss_100_antonym = f'{np.mean(miss_100_antonym):.2f} +- {np.std(miss_100_antonym):.2f}'.split('+-')\n",
    "\n",
    "    line = f'& {model_name_dict[model_name]} ' + \\\n",
    "    f'& {average_miss_1_synonym[0].strip()}$\\pm${average_miss_1_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_synonym[0].strip()}$\\pm${average_miss_10_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_synonym[0].strip()}$\\pm${average_miss_100_synonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_1_antonym[0].strip()}$\\pm${average_miss_1_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_10_antonym[0].strip()}$\\pm${average_miss_10_antonym[1].strip()} ' + \\\n",
    "    f'& {average_miss_100_antonym[0].strip()}$\\pm${average_miss_100_antonym[1].strip()}\\\\\\\\'\n",
    "\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factual_knowledge_probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
