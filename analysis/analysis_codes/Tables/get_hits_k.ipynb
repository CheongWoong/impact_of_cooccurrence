{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average hits@1 for all models\n",
    "Set dataset_name, dataset_type, training_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_dict = {\n",
    "    'bert-base-uncased': 'BERT$_{base}$',\n",
    "    'bert-large-uncased': 'BERT$_{large}$',\n",
    "    'albert-base-v1': 'ALBERT1$_{base}$',\n",
    "    'albert-large-v1': 'ALBERT1$_{large}$',\n",
    "    'albert-xlarge-v1': 'ALBERT1$_{xlarge}$',\n",
    "    'albert-base-v2': 'ALBERT2$_{base}$',\n",
    "    'albert-large-v2': 'ALBERT2$_{large}$',\n",
    "    'albert-xlarge-v2': 'ALBERT2$_{xlarge}$',\n",
    "    'roberta-base': 'RoBERTa$_{base}$',\n",
    "    'roberta-large': 'RoBERTa$_{large}$',\n",
    "    'gpt-neo-125m': 'GPT-Neo 125M',\n",
    "    'gpt-neo-1.3B': 'GPT-Neo 1.3B',\n",
    "    'gpt-neo-2.7B': 'GPT-Neo 2.7B',\n",
    "    'gpt-j-6b': 'GPT-J 6B',\n",
    "    'gpt-3.5-turbo-0125': 'ChatGPT-3.5',\n",
    "    'gpt-4-0125-preview': 'ChatGPT-4'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LAMA_TREx'\n",
    "dataset_type = 'test_4_shot'\n",
    "\n",
    "training_type = 'zeroshot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_name_dict.keys():\n",
    "    try:\n",
    "        data = json.load(open(f'../../../results/{dataset_name}/{model_name}_{dataset_name}_{training_type}/score_{dataset_name}_{dataset_type}.json', 'r'))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    micro_hits_1 = data['hits@1_remove_stopwords'].split('+-')\n",
    "    micro_hits_10 = data['hits@10_remove_stopwords'].split('+-')\n",
    "    micro_hits_100 = data['hits@100_remove_stopwords'].split('+-')\n",
    "\n",
    "    relation_wise_hits_1, relation_wise_hits_10, relation_wise_hits_100 = [], [], []\n",
    "    for key in data:\n",
    "        if key.startswith('hits@1_remove_stopwords_'):\n",
    "            relation_wise_hits_1.append(float(data[key].split('+-')[0]))\n",
    "        elif key.startswith('hits@10_remove_stopwords_'):\n",
    "            relation_wise_hits_10.append(float(data[key].split('+-')[0]))\n",
    "        elif key.startswith('hits@100_remove_stopwords_'):\n",
    "            relation_wise_hits_100.append(float(data[key].split('+-')[0]))\n",
    "\n",
    "    macro_hits_1 = f'{np.mean(relation_wise_hits_1):.2f} +- {np.std(relation_wise_hits_1):.2f}'.split('+-')\n",
    "    macro_hits_10 = f'{np.mean(relation_wise_hits_10):.2f} +- {np.std(relation_wise_hits_10):.2f}'.split('+-')\n",
    "    macro_hits_100 = f'{np.mean(relation_wise_hits_100):.2f} +- {np.std(relation_wise_hits_100):.2f}'.split('+-')\n",
    "\n",
    "    line = f'& {model_name_dict[model_name]} ' + \\\n",
    "    f'& {micro_hits_1[0].strip()}$\\pm${micro_hits_1[1].strip()} ' + \\\n",
    "    f'& {micro_hits_10[0].strip()}$\\pm${micro_hits_10[1].strip()} ' + \\\n",
    "    f'& {micro_hits_100[0].strip()}$\\pm${micro_hits_100[1].strip()} ' + \\\n",
    "    f'& {macro_hits_1[0].strip()}$\\pm${macro_hits_1[1].strip()} ' + \\\n",
    "    f'& {macro_hits_10[0].strip()}$\\pm${macro_hits_10[1].strip()} ' + \\\n",
    "    f'& {macro_hits_100[0].strip()}$\\pm${macro_hits_100[1].strip()}\\\\\\\\'\n",
    "\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation-wise hits@1 for a pre-defined group of models\n",
    "Set dataset_name, dataset_type, training_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the group of model names for each run\n",
    "# model_names = ['bert-base-uncased', 'bert-large-uncased']\n",
    "# model_names = ['albert-base-v1', 'albert-large-v1', 'albert-xlarge-v1']\n",
    "# model_names = ['albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2']\n",
    "# model_names = ['roberta-base', 'roberta-large']\n",
    "# model_names = ['gpt-neo-125m', 'gpt-neo-1.3B', 'gpt-neo-2.7B']\n",
    "model_names = ['gpt-j-6b', 'gpt-3.5-turbo-0125', 'gpt-4-0125-preview']\n",
    "\n",
    "# model_names = ['bert-base-uncased', 'bert-large-uncased']\n",
    "# model_names = ['gpt-neo-125m', 'gpt-j-6b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ConceptNet'\n",
    "dataset_type = 'test'\n",
    "\n",
    "training_type = 'zeroshot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_wise_line = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    data = json.load(open(f'../../../results/{dataset_name}/{model_name}_{dataset_name}_{training_type}/score_{dataset_name}_{dataset_type}.json', 'r'))\n",
    "\n",
    "    relation_wise_hits_1, relation_wise_hits_10, relation_wise_hits_100 = {}, {}, {}\n",
    "    for key in data:\n",
    "        if key.startswith('hits@1_remove_stopwords_'):\n",
    "            rel_id = key.split('hits@1_remove_stopwords_')[1]\n",
    "            relation_wise_hits_1[rel_id] = data[key].split('+-')\n",
    "        elif key.startswith('hits@10_remove_stopwords_'):\n",
    "            rel_id = key.split('hits@10_remove_stopwords_')[1]\n",
    "            relation_wise_hits_10[rel_id] = data[key].split('+-')\n",
    "        elif key.startswith('hits@100_remove_stopwords_'):\n",
    "            rel_id = key.split('hits@100_remove_stopwords_')[1]\n",
    "            relation_wise_hits_100[rel_id] = data[key].split('+-')\n",
    "\n",
    "    for rel_id in sorted(list(relation_wise_hits_1.keys())):\n",
    "        if rel_id not in relation_wise_line:\n",
    "            relation_wise_line[rel_id] = rel_id\n",
    "        line = f' & {relation_wise_hits_1[rel_id][0].strip()}$\\pm${relation_wise_hits_1[rel_id][1].strip()}' + \\\n",
    "        f' & {relation_wise_hits_10[rel_id][0].strip()}$\\pm${relation_wise_hits_10[rel_id][1].strip()}' + \\\n",
    "        f' & {relation_wise_hits_100[rel_id][0].strip()}$\\pm${relation_wise_hits_100[rel_id][1].strip()}'\n",
    "        \n",
    "        relation_wise_line[rel_id] += line\n",
    "\n",
    "for rel_id in relation_wise_line:\n",
    "    relation_wise_line[rel_id] += '\\\\\\\\'\n",
    "\n",
    "for line in relation_wise_line.values():\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average hits@1 for term frequency baselines\n",
    "Set pretraining_dataset_name, dataset_name, dataset_type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['marginal', 'joint', 'pmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretraining_dataset_name = 'bert_pretraining_data'\n",
    "\n",
    "dataset_name = 'ConceptNet'\n",
    "dataset_type = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    try:\n",
    "        data = json.load(open(f'../../../results/{dataset_name}/{model_name}/{pretraining_dataset_name}/score_{dataset_name}_{dataset_type}.json', 'r'))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for type in ['remove_stopwords', 'gold_objs', 'gold_objs_relation_wise']:\n",
    "        micro_hits_1 = data[f'hits@1_{type}'].split('+-')\n",
    "        micro_hits_10 = data[f'hits@10_{type}'].split('+-')\n",
    "        micro_hits_100 = data[f'hits@100_{type}'].split('+-')\n",
    "\n",
    "        relation_wise_hits_1, relation_wise_hits_10, relation_wise_hits_100 = [], [], []\n",
    "        for key in data:\n",
    "            if key.startswith(f'hits@1_{type}_'):\n",
    "                relation_wise_hits_1.append(float(data[key].split('+-')[0]))\n",
    "            elif key.startswith(f'hits@10_{type}_'):\n",
    "                relation_wise_hits_10.append(float(data[key].split('+-')[0]))\n",
    "            elif key.startswith(f'hits@100_{type}_'):\n",
    "                relation_wise_hits_100.append(float(data[key].split('+-')[0]))\n",
    "\n",
    "        macro_hits_1 = f'{np.mean(relation_wise_hits_1):.2f} +- {np.std(relation_wise_hits_1):.2f}'.split('+-')\n",
    "        macro_hits_10 = f'{np.mean(relation_wise_hits_10):.2f} +- {np.std(relation_wise_hits_10):.2f}'.split('+-')\n",
    "        macro_hits_100 = f'{np.mean(relation_wise_hits_100):.2f} +- {np.std(relation_wise_hits_100):.2f}'.split('+-')\n",
    "\n",
    "        line = f'& {model_name} ' + \\\n",
    "        f'& {micro_hits_1[0].strip()}$\\pm${micro_hits_1[1].strip()} ' + \\\n",
    "        f'& {micro_hits_10[0].strip()}$\\pm${micro_hits_10[1].strip()} ' + \\\n",
    "        f'& {micro_hits_100[0].strip()}$\\pm${micro_hits_100[1].strip()} ' + \\\n",
    "        f'& {macro_hits_1[0].strip()}$\\pm${macro_hits_1[1].strip()} ' + \\\n",
    "        f'& {macro_hits_10[0].strip()}$\\pm${macro_hits_10[1].strip()} ' + \\\n",
    "        f'& {macro_hits_100[0].strip()}$\\pm${macro_hits_100[1].strip()}\\\\\\\\'\n",
    "\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "factual_knowledge_probing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
